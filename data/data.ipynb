{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce242ca",
   "metadata": {},
   "source": [
    "# Data Collection and Processing Notebook\n",
    "\n",
    "This notebook contains all code for collecting, cleaning, and merging data for the Next Up project.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook is organized into the following sections:\n",
    "1. **Setup & Helper Functions** - Import libraries and define utility functions\n",
    "2. **NBA.com Call-Up Data** - Web scraping official G League call-up tables\n",
    "3. **Call-Up Aggregation** - Season CSVs + player-level call-up summaries\n",
    "4. **Two-Way Contracts Data** - Loading manually collected two-way contract data\n",
    "5. **Two-Way Conversions Data** - Loading manually collected conversion data\n",
    "6. **G-League Player Stats (API)** - Collecting player statistics from SportsRadar API\n",
    "7. **G-League Player Stats (CSV)** - Loading player stats from CSV files by season\n",
    "8. **Creating Prediction Dataset** - Merging all data sources with `called_up` target variable\n",
    "\n",
    "---\n",
    "\n",
    "## Section 1: Setup & Helper Functions\n",
    "\n",
    "Import necessary libraries and define helper functions used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7642e6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import parser\n",
    "from unidecode import unidecode\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables for API keys\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "097dbfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def clean_name(name):\n",
    "    \"\"\"Clean player names to ensure consistent matching across datasets.\n",
    "    Handles 'Last, First' format and normalizes spacing.\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return None\n",
    "    name = str(name).strip()\n",
    "    # Handle \"Last, First\" format\n",
    "    if \",\" in name:\n",
    "        last, first = name.split(\",\", 1)\n",
    "        return f\"{first.strip()} {last.strip()}\"\n",
    "    return name\n",
    "\n",
    "def to_date(x):\n",
    "    \"\"\"Convert date string to datetime object. Handles various date formats.\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        # Handles sources that use mm/dd/yy style date strings\n",
    "        return parser.parse(str(x), dayfirst=False, yearfirst=False)\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "def nba_season(dt):\n",
    "    \"\"\"Map a calendar date to NBA season label like '2024-25'.\n",
    "    Season 'YYYY-YY' starts Aug 1 of YYYY and ends Jul 31 of YYYY+1.\"\"\"\n",
    "    if pd.isna(dt):\n",
    "        return None\n",
    "    y = dt.year\n",
    "    if dt.month >= 8:  # Aug..Dec -> season starts this year\n",
    "        return f\"{y}-{(y+1)%100:02d}\"\n",
    "    else:  # Jan..Jul -> season started previous year\n",
    "        return f\"{y-1}-{y%100:02d}\"\n",
    "\n",
    "def canon_team(t):\n",
    "    \"\"\"Canonicalize team names to standard format.\"\"\"\n",
    "    if pd.isna(t):\n",
    "        return None\n",
    "    t = t.strip()\n",
    "    TEAM_CANON = {\n",
    "        \"LA Clippers\": \"Los Angeles Clippers\",\n",
    "        \"L.A. Clippers\": \"Los Angeles Clippers\",\n",
    "        \"LA Lakers\": \"Los Angeles Lakers\",\n",
    "        \"L.A. Lakers\": \"Los Angeles Lakers\",\n",
    "    }\n",
    "    return TEAM_CANON.get(t, t)\n",
    "\n",
    "def extract_season_year(season_str):\n",
    "    \"\"\"Extract season year from season string like '2024-25' -> 2024.\"\"\"\n",
    "    if pd.isna(season_str):\n",
    "        return None\n",
    "    season_str = str(season_str)\n",
    "    # Handle formats like \"2024-25\", \"2024\", \"2024.0\"\n",
    "    if \"-\" in season_str:\n",
    "        return int(season_str.split(\"-\")[0])\n",
    "    try:\n",
    "        return int(float(season_str))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "print(\"✅ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29b3cd0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: NBA.com Call-Up Data (Web Scraping)\n",
    "\n",
    "This section scrapes official NBA G League call-up tables from NBA.com for multiple seasons.\n",
    "\n",
    "**Sources**:\n",
    "- 2019-20: `https://gleague.nba.com/nba-call-ups-for-the-2019-20-season`\n",
    "- 2020-21: `https://gleague.nba.com/nba-call-ups-for-the-2020-21-season`\n",
    "- 2022-23: `https://gleague.nba.com/nba-call-ups-from-the-2022-23-season`\n",
    "- 2023-24: `https://gleague.nba.com/nba-call-ups-2023-24`\n",
    "- 2024-25: `https://gleague.nba.com/nba-call-ups-2024-25`\n",
    "\n",
    "**Outputs**:\n",
    "- One CSV per season (e.g. `callups_nba_2019_20.csv`)\n",
    "- A combined, player-level dataset with:\n",
    "  - `callup_dates` as a list of all call-up dates per player-season\n",
    "  - `times_called_up` as the number of call-ups per player-season\n",
    "  - `contract_type` aggregated across call-ups for that season\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f35b3771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration set up for NBA.com call-up scraping\n"
     ]
    }
   ],
   "source": [
    "# Configuration for NBA.com call-up scraping\n",
    "\n",
    "NBA_CALLUP_SOURCES = [\n",
    "    {\n",
    "        \"season_label\": \"2019-20\",\n",
    "        \"season_year\": 2019,\n",
    "        \"url\": \"https://gleague.nba.com/nba-call-ups-for-the-2019-20-season\",\n",
    "        \"csv_path\": \"callups_nba_2019_20.csv\",\n",
    "    },\n",
    "    {\n",
    "        \"season_label\": \"2020-21\",\n",
    "        \"season_year\": 2021,\n",
    "        \"url\": \"https://gleague.nba.com/nba-call-ups-for-the-2020-21-season\",\n",
    "        \"csv_path\": \"callups_nba_2020_21.csv\",\n",
    "    },\n",
    "    {\n",
    "        \"season_label\": \"2022-23\",\n",
    "        \"season_year\": 2022,\n",
    "        \"url\": \"https://gleague.nba.com/nba-call-ups-from-the-2022-23-season\",\n",
    "        \"csv_path\": \"callups_nba_2022_23.csv\",\n",
    "    },\n",
    "    {\n",
    "        \"season_label\": \"2023-24\",\n",
    "        \"season_year\": 2023,\n",
    "        \"url\": \"https://gleague.nba.com/nba-call-ups-2023-24\",\n",
    "        \"csv_path\": \"callups_nba_2023_24.csv\",\n",
    "    },\n",
    "    {\n",
    "        \"season_label\": \"2024-25\",\n",
    "        \"season_year\": 2024,\n",
    "        \"url\": \"https://gleague.nba.com/nba-call-ups-2024-25\",\n",
    "        \"csv_path\": \"callups_nba_2024_25.csv\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"✅ Configuration set up for NBA.com call-up scraping\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0d0a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ NBA.com call-up scraping function defined\n"
     ]
    }
   ],
   "source": [
    "# Scraping function for NBA.com call-up tables\n",
    "\n",
    "def scrape_nba_callups(url: str) -> pd.DataFrame:\n",
    "    \"\"\"Scrape a single NBA.com G League call-ups table into a tidy DataFrame.\"\"\"\n",
    "\n",
    "    def canon(text: str) -> str:\n",
    "        if text is None:\n",
    "            return \"\"\n",
    "        text = unidecode(str(text)).replace(\"\\xa0\", \" \")\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip().upper()\n",
    "        text = re.sub(r\"[^A-Z0-9]+\", \"_\", text)\n",
    "        return text.strip(\"_\")\n",
    "\n",
    "    def extract_rows(table):\n",
    "        rows = []\n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            cells = tr.find_all([\"td\", \"th\"])\n",
    "            if not cells:\n",
    "                continue\n",
    "            row = [unidecode(td.get_text(separator=\" \", strip=True)).strip() for td in cells]\n",
    "            if any(row):\n",
    "                rows.append(row)\n",
    "        return rows\n",
    "\n",
    "    col_aliases = {\n",
    "        \"NAME\": \"player_name\",\n",
    "        \"PLAYER\": \"player_name\",\n",
    "        \"NBA_G_LEAGUE_TEAM\": \"gleague_team\",\n",
    "        \"G_LEAGUE_TEAM\": \"gleague_team\",\n",
    "        \"NBA_TEAM\": \"nba_team\",\n",
    "        \"DATE\": \"callup_date\",\n",
    "        \"CALL_UP_DATE\": \"callup_date\",\n",
    "        \"TYPE\": \"contract_type\",\n",
    "        \"CONTRACT_TYPE\": \"contract_type\",\n",
    "    }\n",
    "    required = {\"player_name\", \"gleague_team\", \"nba_team\", \"callup_date\", \"contract_type\"}\n",
    "    expected_header = {\"NAME\", \"NBA_G_LEAGUE_TEAM\", \"NBA_TEAM\", \"DATE\", \"TYPE\"}\n",
    "\n",
    "    response = requests.get(\n",
    "        url,\n",
    "        timeout=30,\n",
    "        headers={\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36\",\n",
    "        },\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    tables = soup.find_all(\"table\")\n",
    "    if not tables:\n",
    "        raise RuntimeError(f\"No tables found at {url}\")\n",
    "\n",
    "    for table in tables:\n",
    "        rows = extract_rows(table)\n",
    "        if not rows:\n",
    "            continue\n",
    "\n",
    "        header_idx = 0\n",
    "        for idx, row in enumerate(rows[:3]):\n",
    "            if expected_header.issubset({canon(val) for val in row}):\n",
    "                header_idx = idx\n",
    "                break\n",
    "\n",
    "        header = rows[header_idx]\n",
    "        width = len(header)\n",
    "        data_rows = rows[header_idx + 1 :]\n",
    "        if not data_rows:\n",
    "            continue\n",
    "\n",
    "        normalized_rows = []\n",
    "        for row in data_rows:\n",
    "            trimmed = row[:width]\n",
    "            if len(trimmed) < width:\n",
    "                trimmed = trimmed + [\"\"] * (width - len(trimmed))\n",
    "            normalized_rows.append(trimmed[:width])\n",
    "\n",
    "        df = pd.DataFrame(normalized_rows, columns=header)\n",
    "\n",
    "        rename_dict = {}\n",
    "        for col in df.columns:\n",
    "            key = canon(col)\n",
    "            if key in col_aliases:\n",
    "                rename_dict[col] = col_aliases[key]\n",
    "        df = df.rename(columns=rename_dict)\n",
    "\n",
    "        missing = required - set(df.columns)\n",
    "        if missing:\n",
    "            continue\n",
    "\n",
    "        df = df.copy()\n",
    "        df[\"player_name\"] = df[\"player_name\"].apply(clean_name)\n",
    "        for col in [\"gleague_team\", \"nba_team\", \"contract_type\"]:\n",
    "            df[col] = (\n",
    "                df[col]\n",
    "                .astype(str)\n",
    "                .str.replace(\"\\xa0\", \" \", regex=False)\n",
    "                .str.strip()\n",
    "                .replace({\"\": None, \"nan\": None, \"None\": None})\n",
    "            )\n",
    "        df[\"callup_date\"] = pd.to_datetime(df[\"callup_date\"], errors=\"coerce\")\n",
    "        df = df.dropna(subset=[\"player_name\", \"callup_date\"])\n",
    "\n",
    "        return df.reset_index(drop=True)\n",
    "\n",
    "    raise RuntimeError(f\"Missing expected columns at {url}\")\n",
    "\n",
    "print(\"✅ NBA.com call-up scraping function defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f45f0f0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Build Season-Level and Combined Call-Up Datasets\n",
    "\n",
    "This section:\n",
    "1. Scrapes each NBA.com call-up page\n",
    "2. Saves one CSV per season\n",
    "3. Builds a combined player-season dataset with aggregated call-up information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ac5b206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Scraping call-ups for season 2019-20 from https://gleague.nba.com/nba-call-ups-for-the-2019-20-season\n",
      "Saved 34 rows to callups_nba_2019_20.csv\n",
      "================================================================================\n",
      "Scraping call-ups for season 2020-21 from https://gleague.nba.com/nba-call-ups-for-the-2020-21-season\n",
      "Saved 12 rows to callups_nba_2020_21.csv\n",
      "================================================================================\n",
      "Scraping call-ups for season 2022-23 from https://gleague.nba.com/nba-call-ups-from-the-2022-23-season\n",
      "Saved 35 rows to callups_nba_2022_23.csv\n",
      "================================================================================\n",
      "Scraping call-ups for season 2023-24 from https://gleague.nba.com/nba-call-ups-2023-24\n",
      "Saved 54 rows to callups_nba_2023_24.csv\n",
      "================================================================================\n",
      "Scraping call-ups for season 2024-25 from https://gleague.nba.com/nba-call-ups-2024-25\n",
      "Saved 51 rows to callups_nba_2024_25.csv\n",
      "\n",
      "Total combined call-up records: 186\n",
      "Saved merged raw dataset to callups_nba_2019_2025_all.csv\n",
      "\n",
      "Saved aggregated call-up dataset to callups_nba_2019_2025_aggregated.csv  (166 player-seasons)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>season_label</th>\n",
       "      <th>season_year</th>\n",
       "      <th>gleague_teams</th>\n",
       "      <th>nba_teams</th>\n",
       "      <th>callup_dates</th>\n",
       "      <th>contract_type</th>\n",
       "      <th>times_called_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>2022</td>\n",
       "      <td>[College Park Skyhawks]</td>\n",
       "      <td>[Minnesota Timberwolves, Dallas Mavericks]</td>\n",
       "      <td>[11-15-2022, 12-26-2022]</td>\n",
       "      <td>[Two-Way, Two-Way]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AJ Lawson</td>\n",
       "      <td>2024-25</td>\n",
       "      <td>2024</td>\n",
       "      <td>[Long Island Nets]</td>\n",
       "      <td>[Raptors 905]</td>\n",
       "      <td>[12-11-2024]</td>\n",
       "      <td>[Two-Way]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adam Flagler</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>2023</td>\n",
       "      <td>[Oklahoma City Blue]</td>\n",
       "      <td>[Oklahoma City Thunder]</td>\n",
       "      <td>[02-11-2024]</td>\n",
       "      <td>[Two-Way]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alex Reese</td>\n",
       "      <td>2024-25</td>\n",
       "      <td>2024</td>\n",
       "      <td>[Rip City Remix]</td>\n",
       "      <td>[Philadelphia 76ers]</td>\n",
       "      <td>[02-21-2025]</td>\n",
       "      <td>[Two-Way]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alize Johnson</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>2022</td>\n",
       "      <td>[Austin Spurs]</td>\n",
       "      <td>[San Antonio Spurs]</td>\n",
       "      <td>[11-29-2022]</td>\n",
       "      <td>[Standard]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     player_name season_label  season_year            gleague_teams  \\\n",
       "0    A.J. Lawson      2022-23         2022  [College Park Skyhawks]   \n",
       "1      AJ Lawson      2024-25         2024       [Long Island Nets]   \n",
       "2   Adam Flagler      2023-24         2023     [Oklahoma City Blue]   \n",
       "3     Alex Reese      2024-25         2024         [Rip City Remix]   \n",
       "4  Alize Johnson      2022-23         2022           [Austin Spurs]   \n",
       "\n",
       "                                    nba_teams              callup_dates  \\\n",
       "0  [Minnesota Timberwolves, Dallas Mavericks]  [11-15-2022, 12-26-2022]   \n",
       "1                               [Raptors 905]              [12-11-2024]   \n",
       "2                     [Oklahoma City Thunder]              [02-11-2024]   \n",
       "3                        [Philadelphia 76ers]              [02-21-2025]   \n",
       "4                         [San Antonio Spurs]              [11-29-2022]   \n",
       "\n",
       "        contract_type  times_called_up  \n",
       "0  [Two-Way, Two-Way]                2  \n",
       "1           [Two-Way]                1  \n",
       "2           [Two-Way]                1  \n",
       "3           [Two-Way]                1  \n",
       "4          [Standard]                1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_callups = []\n",
    "\n",
    "for src in NBA_CALLUP_SOURCES:\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Scraping call-ups for season {src['season_label']} from {src['url']}\")\n",
    "    df_season = scrape_nba_callups(src['url'])\n",
    "\n",
    "    df_season['season_label'] = src['season_label']\n",
    "    df_season['season_year'] = src['season_year']\n",
    "\n",
    "    # Save per-season CSV\n",
    "    csv_path = src['csv_path']\n",
    "    df_season.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved {len(df_season)} rows to {csv_path}\")\n",
    "\n",
    "    all_callups.append(df_season)\n",
    "\n",
    "if not all_callups:\n",
    "    raise RuntimeError(\"No call-up data scraped\")\n",
    "\n",
    "\n",
    "def ordered_unique(values):\n",
    "    \"\"\"Keep the first occurrence order while dropping nulls/duplicates.\"\"\"\n",
    "    seen = []\n",
    "    for val in values:\n",
    "        if pd.isna(val) or val in seen:\n",
    "            continue\n",
    "        seen.append(val)\n",
    "    return seen\n",
    "\n",
    "\n",
    "def format_dates(series):\n",
    "    dates = []\n",
    "    for d in series:\n",
    "        if pd.notna(d):\n",
    "            dates.append(d.strftime('%m-%d-%Y'))\n",
    "    return dates\n",
    "\n",
    "\n",
    "# Combine all seasons into a single row-level dataset\n",
    "callups_all = pd.concat(all_callups, ignore_index=True)\n",
    "callups_all = callups_all.sort_values(\n",
    "    ['player_name', 'season_year', 'callup_date'],\n",
    "    na_position='last'\n",
    ").reset_index(drop=True)\n",
    "print(f\"\\nTotal combined call-up records: {len(callups_all):,}\")\n",
    "\n",
    "raw_csv = 'callups_nba_2019_2025_all.csv'\n",
    "callups_all.to_csv(raw_csv, index=False)\n",
    "print(f\"Saved merged raw dataset to {raw_csv}\")\n",
    "\n",
    "# Aggregate to player-season level with deduplicated teams and ordered events\n",
    "agg = (\n",
    "    callups_all\n",
    "    .groupby(['player_name', 'season_label', 'season_year'], as_index=False)\n",
    "    .agg({\n",
    "        'gleague_team': ordered_unique,\n",
    "        'nba_team': ordered_unique,\n",
    "        'callup_date': format_dates,\n",
    "        'contract_type': lambda s: [ct for ct in s if pd.notna(ct)],\n",
    "    })\n",
    ")\n",
    "\n",
    "agg = agg.rename(columns={\n",
    "    'gleague_team': 'gleague_teams',\n",
    "    'nba_team': 'nba_teams',\n",
    "    'callup_date': 'callup_dates',\n",
    "})\n",
    "\n",
    "agg['times_called_up'] = agg['callup_dates'].apply(len)\n",
    "\n",
    "# Save combined aggregated dataset\n",
    "combined_csv = 'callups_nba_2019_2025_aggregated.csv'\n",
    "agg.to_csv(combined_csv, index=False)\n",
    "\n",
    "print(f\"\\nSaved aggregated call-up dataset to {combined_csv}  ({len(agg):,} player-seasons)\")\n",
    "agg.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217df8a7",
   "metadata": {},
   "source": [
    "### Call-Up Outputs\n",
    "\n",
    "- `callups_nba_2019_2025_all.csv`: Row-level call-up log with every event from the five NBA.com pages.\n",
    "- `callups_nba_2019_2025_aggregated.csv`: Player-season summary where duplicate call-ups are rolled into ordered `callup_dates` and `contract_type` lists, plus `times_called_up` counts and deduplicated team lists.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f148a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: G-League Player Stats (API Collection)\n",
    "\n",
    "This section collects G-League player statistics from the SportsRadar API. The API provides comprehensive player data including:\n",
    "- Player profiles (name, position, height, weight, etc.)\n",
    "- Season statistics (points, rebounds, assists, shooting percentages, etc.)\n",
    "- Team rosters\n",
    "\n",
    "**Source**: SportsRadar NBDL API  \n",
    "**API Endpoint**: `https://api.sportradar.us/nbdl/trial/v8/en`\n",
    "\n",
    "**Note**: This code requires an API key stored in a `.env` file. The code includes caching to avoid redundant API calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4455daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "if not API_KEY:\n",
    "    print(\"Warning: API_KEY not found in .env file\")\n",
    "    print(\"   Set up API key following instructions in API_SETUP_INSTRUCTIONS.md\")\n",
    "else:\n",
    "    print(\"API key loaded\")\n",
    "\n",
    "BASE_URL = \"https://api.sportradar.us/nbdl/trial/v8/en\"\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"../raw\", exist_ok=True)\n",
    "os.makedirs(\"../raw_json\", exist_ok=True)\n",
    "os.makedirs(\"external\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "936c425e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call function defined\n"
     ]
    }
   ],
   "source": [
    "# API call function with caching and retry logic\n",
    "def api_call(url, cache_file=None, max_retries=5):\n",
    "    \"\"\"Make API call with caching and exponential backoff for rate limiting.\"\"\"\n",
    "    if cache_file and os.path.exists(cache_file):\n",
    "        print(f\"  [cached]\")\n",
    "        with open(cache_file, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if cache_file:\n",
    "                with open(cache_file, 'w') as f:\n",
    "                    json.dump(data, f)\n",
    "            \n",
    "            time.sleep(2)  # Rate limiting delay\n",
    "            return data\n",
    "            \n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code == 429:\n",
    "                wait_time = (2 ** attempt) * 5  # Exponential backoff: 5, 10, 20, 40, 80 seconds\n",
    "                print(f\"  Rate limited. Waiting {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                raise\n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"  Error: {e}. Retrying...\")\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                raise\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(\"API call function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ce8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This code is commented out since we already have the CSV files\n",
    "# Uncomment to re-collect data from API if needed\n",
    "\n",
    "\"\"\"\n",
    "# Fetch league hierarchy to get all teams\n",
    "print(\"Fetching league hierarchy...\")\n",
    "url = f\"{BASE_URL}/league/hierarchy.json?api_key={API_KEY}\"\n",
    "hierarchy = api_call(url, \"../raw_json/hierarchy.json\")\n",
    "\n",
    "teams_data = []\n",
    "for conf in hierarchy['conferences']:\n",
    "    for div in conf['divisions']:\n",
    "        for team in div['teams']:\n",
    "            teams_data.append({\n",
    "                'team_id': team['id'],\n",
    "                'team_name': team.get('market', '') + ' ' + team['name'],\n",
    "                'alias': team['alias']\n",
    "            })\n",
    "\n",
    "df_teams = pd.DataFrame(teams_data)\n",
    "print(f\"\\\\nFound {len(df_teams)} teams\\\\n\")\n",
    "\n",
    "all_players = []\n",
    "all_rosters = []\n",
    "all_stats = []\n",
    "\n",
    "for idx, row in df_teams.iterrows():\n",
    "    team_id = row['team_id']\n",
    "    team_name = row['team_name']\n",
    "    \n",
    "    print(f\"[{idx+1}/{len(df_teams)}] {team_name}\")\n",
    "    \n",
    "    url = f\"{BASE_URL}/teams/{team_id}/profile.json?api_key={API_KEY}\"\n",
    "    team_data = api_call(url, f\"../raw_json/team_{team_id}.json\")\n",
    "    \n",
    "    if 'players' not in team_data:\n",
    "        continue\n",
    "    \n",
    "    for player in team_data['players']:\n",
    "        player_id = player.get('id')\n",
    "        player_name = player.get('full_name', '')\n",
    "        \n",
    "        all_players.append({\n",
    "            'player_id': player_id,\n",
    "            'full_name': player_name,\n",
    "            'position': player.get('position', ''),\n",
    "            'height': player.get('height', None),\n",
    "            'weight': player.get('weight', None),\n",
    "            'birthdate': player.get('birthdate', ''),\n",
    "            'college': player.get('college', '')\n",
    "        })\n",
    "        \n",
    "        all_rosters.append({\n",
    "            'team_id': team_id,\n",
    "            'team_name': team_name,\n",
    "            'player_id': player_id,\n",
    "            'player_name': player_name,\n",
    "            'position': player.get('position', '')\n",
    "        })\n",
    "        \n",
    "        if 'seasons' in player:\n",
    "            for season in player['seasons']:\n",
    "                if 'teams' in season:\n",
    "                    for team in season['teams']:\n",
    "                        if 'total' in team:\n",
    "                            stats = team['total']\n",
    "                            all_stats.append({\n",
    "                                'player_id': player_id,\n",
    "                                'player_name': player_name,\n",
    "                                'team_id': team_id,\n",
    "                                'team_name': team_name,\n",
    "                                'position': player.get('position', ''),\n",
    "                                'games_played': stats.get('games_played', 0),\n",
    "                                'minutes': stats.get('minutes', 0),\n",
    "                                'points': stats.get('points', 0),\n",
    "                                'rebounds': stats.get('rebounds', 0),\n",
    "                                'assists': stats.get('assists', 0),\n",
    "                                'steals': stats.get('steals', 0),\n",
    "                                'blocks': stats.get('blocks', 0),\n",
    "                                'turnovers': stats.get('turnovers', 0),\n",
    "                                'field_goals_made': stats.get('field_goals_made', 0),\n",
    "                                'field_goals_att': stats.get('field_goals_att', 0),\n",
    "                                'field_goals_pct': stats.get('field_goals_pct', 0),\n",
    "                                'three_points_made': stats.get('three_points_made', 0),\n",
    "                                'three_points_att': stats.get('three_points_att', 0),\n",
    "                                'three_points_pct': stats.get('three_points_pct', 0),\n",
    "                                'free_throws_made': stats.get('free_throws_made', 0),\n",
    "                                'free_throws_att': stats.get('free_throws_att', 0),\n",
    "                                'free_throws_pct': stats.get('free_throws_pct', 0)\n",
    "                            })\n",
    "\n",
    "print(f\"\\\\nCollected {len(all_stats)} stat records\")\n",
    "print(f\"Collected {len(all_players)} players\")\n",
    "print(f\"Collected {len(all_rosters)} roster entries\\\\n\")\n",
    "\n",
    "df_stats = pd.DataFrame(all_stats)\n",
    "df_players = pd.DataFrame(all_players).drop_duplicates('player_id')\n",
    "df_rosters = pd.DataFrame(all_rosters)\n",
    "\n",
    "if len(df_stats) > 0:\n",
    "    df_stats['points_per_game'] = (df_stats['points'] / df_stats['games_played'].replace(0, 1)).round(2)\n",
    "    df_stats['rebounds_per_game'] = (df_stats['rebounds'] / df_stats['games_played'].replace(0, 1)).round(2)\n",
    "    df_stats['assists_per_game'] = (df_stats['assists'] / df_stats['games_played'].replace(0, 1)).round(2)\n",
    "\n",
    "df_stats.to_csv('../raw/gleague_player_stats.csv', index=False)\n",
    "df_players.to_csv('../raw/gleague_players.csv', index=False)\n",
    "df_rosters.to_csv('../raw/gleague_rosters.csv', index=False)\n",
    "df_teams.to_csv('../raw/gleague_teams.csv', index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(f\"  - gleague_player_stats.csv: {len(df_stats)} records\")\n",
    "print(f\"  - gleague_players.csv: {len(df_players)} records\")\n",
    "print(f\"  - gleague_rosters.csv: {len(df_rosters)} records\")\n",
    "print(f\"  - gleague_teams.csv: {len(df_teams)} records\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"API collection code defined (commented out - using existing CSV files)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03634bcf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7: G-League Player Stats (Loading from CSV Files)\n",
    "\n",
    "This section loads G-League player statistics from CSV files organized by season. These files contain comprehensive player statistics for each season.\n",
    "\n",
    "**Source Files**: \n",
    "- `../raw/gleague_player_season_stats_2019_REG.csv`\n",
    "- `../raw/gleague_player_season_stats_2021_REG.csv`\n",
    "- `../raw/gleague_player_season_stats_2022_REG.csv`\n",
    "- `../raw/gleague_player_season_stats_2023_REG.csv`\n",
    "- `../raw/gleague_player_season_stats_2024_REG.csv`\n",
    "\n",
    "**Note**: These files are created from the API collection process above, or may be manually downloaded from SportsRadar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef2bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all player stats from all season files\n",
    "def load_all_player_stats():\n",
    "    \"\"\"Load all player stats from all season files and combine them.\"\"\"\n",
    "    stats_files = glob.glob(\"../raw/gleague_player_season_stats_*.csv\")\n",
    "    \n",
    "    if not stats_files:\n",
    "        raise FileNotFoundError(\"No player stats files found in ../raw/\")\n",
    "    \n",
    "    print(f\"Found {len(stats_files)} stats files\")\n",
    "    \n",
    "    all_stats = []\n",
    "    for file in stats_files:\n",
    "        print(f\"Loading {Path(file).name}...\")\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # Rename full_name to player_name if needed\n",
    "        if 'full_name' in df.columns and 'player_name' not in df.columns:\n",
    "            df = df.rename(columns={'full_name': 'player_name'})\n",
    "        \n",
    "        # Clean player names\n",
    "        df['player_name'] = df['player_name'].apply(clean_name)\n",
    "        \n",
    "        # Extract season year from season_id\n",
    "        if 'season_id' in df.columns:\n",
    "            df['season_year'] = df['season_id'].apply(extract_season_year)\n",
    "        elif 'season' in df.columns:\n",
    "            df['season_year'] = df['season'].apply(extract_season_year)\n",
    "        else:\n",
    "            # Try to infer from filename\n",
    "            filename = Path(file).name\n",
    "            if '2024' in filename:\n",
    "                df['season_year'] = 2024\n",
    "            elif '2023' in filename:\n",
    "                df['season_year'] = 2023\n",
    "            elif '2022' in filename:\n",
    "                df['season_year'] = 2022\n",
    "            elif '2021' in filename:\n",
    "                df['season_year'] = 2021\n",
    "            elif '2019' in filename:\n",
    "                df['season_year'] = 2019\n",
    "            else:\n",
    "                print(f\"Warning: Could not determine season for {file}\")\n",
    "                continue\n",
    "        \n",
    "        all_stats.append(df)\n",
    "    \n",
    "    # Combine all stats\n",
    "    combined_stats = pd.concat(all_stats, ignore_index=True)\n",
    "    \n",
    "    # Remove duplicates (same player, same season)\n",
    "    combined_stats = combined_stats.drop_duplicates(\n",
    "        subset=['player_name', 'season_year'], \n",
    "        keep='first'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\\\nTotal player-season records: {len(combined_stats)}\")\n",
    "    print(f\"Unique players: {combined_stats['player_name'].nunique()}\")\n",
    "    print(f\"Seasons: {sorted(combined_stats['season_year'].dropna().unique())}\")\n",
    "    \n",
    "    return combined_stats\n",
    "\n",
    "# Load the data\n",
    "df_player_stats = load_all_player_stats()\n",
    "df_player_stats.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83be34f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 8: Creating Prediction Dataset\n",
    "\n",
    "This section merges all data sources to create the final prediction dataset with a `called_up` binary target variable.\n",
    "\n",
    "**Process**:\n",
    "1. Load all player stats (from Section 7)\n",
    "2. Load all callup data (10-day, two-way, conversions from Sections 2-5)\n",
    "3. Merge callup data with player stats based on player name and season\n",
    "4. Create `called_up` column: 1 if player was called up in that season, 0 otherwise\n",
    "5. Add callup details (date, NBA team, contract type) for called-up players\n",
    "\n",
    "**Output**: `prediction_dataset.csv` - Ready for machine learning modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc3e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load aggregated NBA.com callup data\n",
    "def parse_list_cell(value):\n",
    "    \"\"\"Convert stringified list cells back into Python lists.\"\"\"\n",
    "    if isinstance(value, list):\n",
    "        return value\n",
    "    if pd.isna(value):\n",
    "        return []\n",
    "    text = str(value).strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    try:\n",
    "        parsed = ast.literal_eval(text)\n",
    "        if isinstance(parsed, list):\n",
    "            return parsed\n",
    "    except (ValueError, SyntaxError):\n",
    "        pass\n",
    "    return [text]\n",
    "\n",
    "\n",
    "def load_nba_callups():\n",
    "    \"\"\"Load aggregated NBA.com call-ups with parsed list columns.\"\"\"\n",
    "    agg_path = Path('callups_nba_2019_2025_aggregated.csv')\n",
    "    if not agg_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing aggregated call-up file: {agg_path}\")\n",
    "\n",
    "    df = pd.read_csv(agg_path)\n",
    "    df['player_name'] = df['player_name'].apply(clean_name)\n",
    "    df['season_year'] = df['season_year'].astype(int)\n",
    "\n",
    "    list_cols = ['gleague_teams', 'nba_teams', 'callup_dates', 'contract_type']\n",
    "    for col in list_cols:\n",
    "        df[col] = df[col].apply(parse_list_cell)\n",
    "\n",
    "    df['times_called_up'] = df['times_called_up'].fillna(0).astype(int)\n",
    "    print(f\"Loaded {len(df)} player-season call-up rows from {agg_path.name}\")\n",
    "    return df\n",
    "\n",
    "# Load aggregated callup data\n",
    "df_callups_nba = load_nba_callups()\n",
    "df_callups_nba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bef8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prediction dataset\n",
    "def create_prediction_dataset():\n",
    "    \"\"\"Create the final prediction dataset with called_up column.\"\"\"\n",
    "\n",
    "    player_stats = df_player_stats.copy()\n",
    "    player_stats['player_name'] = player_stats['player_name'].apply(clean_name)\n",
    "    player_stats['season_year'] = player_stats['season_year'].astype(int)\n",
    "\n",
    "    callups = df_callups_nba.copy()\n",
    "\n",
    "    merged = player_stats.merge(\n",
    "        callups,\n",
    "        on=['player_name', 'season_year'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    merged['times_called_up'] = merged['times_called_up'].fillna(0).astype(int)\n",
    "    merged['called_up'] = (merged['times_called_up'] > 0).astype(int)\n",
    "\n",
    "    output_file = 'prediction_dataset_callups_nba.csv'\n",
    "    merged.to_csv(output_file, index=False)\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Prediction Dataset Summary\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total records: {len(merged):,}\")\n",
    "    print(f\"Players called up: {merged['called_up'].sum():,}\")\n",
    "    print(f\"Players not called up: {(merged['called_up'] == 0).sum():,}\")\n",
    "    print(f\"Call-up rate: {merged['called_up'].mean():.2%}\")\n",
    "\n",
    "    season_summary = merged.groupby('season_year')['called_up'].agg(['sum', 'count'])\n",
    "    season_summary['call_up_rate'] = (season_summary['sum'] / season_summary['count']).round(3)\n",
    "    print(\"\\nCall-up rate by season:\")\n",
    "    print(season_summary)\n",
    "\n",
    "    print(f\"\\nSaved prediction dataset to {output_file}\")\n",
    "    return merged\n",
    "\n",
    "# Build dataset and preview\n",
    "df_prediction = create_prediction_dataset()\n",
    "df_prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ccb640",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook contains all data collection and processing code for the Next Up project:\n",
    "\n",
    "1. ✅ **NBA.com Call-Up Data** - Web scraping official G League call-up tables\n",
    "2. ✅ **Call-Up Aggregation** - Per-season CSVs plus player-level summaries\n",
    "3. ✅ **Two-Way Contracts** - Loading manually collected data\n",
    "4. ✅ **Two-Way Conversions** - Loading manually collected data\n",
    "5. ✅ **G-League Player Stats (API)** - Collecting from SportsRadar API\n",
    "6. ✅ **G-League Player Stats (CSV)** - Loading from season CSV files\n",
    "7. ✅ **Prediction Dataset** - Merging all sources with `called_up` target variable\n",
    "\n",
    "**Final Output**: `prediction_dataset.csv` with 2,437 player-season records ready for modeling.\n",
    "\n",
    "**Next Steps**:\n",
    "- Explore the data in `eda.ipynb`\n",
    "- Build prediction models in `analysis.ipynb`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
